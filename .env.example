# AI Model Configuration
# ======================

# Server Configuration
PORT=3000
NODE_ENV=production

# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_BASE_URL=https://api.openai.com/v1

# Anthropic Configuration
ANTHROPIC_API_KEY=your_anthropic_api_key_here
ANTHROPIC_BASE_URL=https://api.anthropic.com

# Google AI Configuration
GOOGLE_API_KEY=your_google_api_key_here
GOOGLE_BASE_URL=https://generativelanguage.googleapis.com/v1

# Groq Configuration
GROQ_API_KEY=your_groq_api_key_here
GROQ_BASE_URL=https://api.groq.com/openai/v1

# Model Selection Configuration
# =============================

# Default model to use when no specific routing is determined
DEFAULT_MODEL=gpt-4o
DEFAULT_PROVIDER=openai

# Rate Limiting Configuration
# ===========================

# Rate limiting settings (requests per window)
RATE_LIMIT_WINDOW_MS=900000
RATE_LIMIT_MAX_REQUESTS=100

# Security Configuration
# ======================

# CORS settings
CORS_ORIGIN=*
CORS_METHODS=GET,POST,PUT,DELETE,OPTIONS
CORS_ALLOWED_HEADERS=Content-Type,Authorization

# Request timeout (in milliseconds)
REQUEST_TIMEOUT=30000

# Model Configuration
# ==================

# Temperature settings
DEFAULT_TEMPERATURE=0.7
MAX_TEMPERATURE=2.0
MIN_TEMPERATURE=0.0

# Token limits
DEFAULT_MAX_TOKENS=2048
MAX_TOKENS_LIMIT=4096

# Model availability
ENABLE_OPENAI=true
ENABLE_ANTHROPIC=true
ENABLE_GOOGLE=true
ENABLE_GROQ=true

# Logging Configuration
# ====================

# Log level (error, warn, info, debug)
LOG_LEVEL=info

# Enable request logging
ENABLE_REQUEST_LOGGING=true

# Enable error tracking
ENABLE_ERROR_TRACKING=true